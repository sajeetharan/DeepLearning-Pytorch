{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM Example**\n",
    "<img src=\"svm_ex.png\" alt=\"Drawing\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**A hyperplane in space is defined as**\n",
    "<font size=\"3\">\n",
    "$$\\mathbf{w}^T\\mathbf{x} + b = 0$$ \n",
    "</font>\n",
    "**SVM Margin**\n",
    "<font size=\"3\">\n",
    "$$margin = \\underset{x}{min}\\; \\frac{y_n(\\mathbf{w}^Tx_n+b)}{{\\left \\| \\mathbf{w} \\right \\|}_2}$$\n",
    "\n",
    "_SVM optimization is the problem of finding $\\mathbf{w}$ and $b$ such that $margin$ is maximized._\n",
    "\\begin{equation}\n",
    "\\tag{1}\n",
    "(\\mathbf{w},b) = arg\\;\\underset{\\mathbf{w},b}{max}\\left \\{ \\underset{n}{min}\\;\\frac{y_n(\\mathbf{w}^Tx_n+b)}{{\\left \\| \\mathbf{w} \\right \\|}_2} \\right \\}= arg\\;\\underset{\\mathbf{w},b}{max}\\left \\{\\frac{1}{{{\\left \\| \\mathbf{w} \\right \\|}_2}} \\underset{n}{min}\\;y_n(\\mathbf{w}^Tx_n+b) \\right \\}\n",
    "\\end{equation}\n",
    "\n",
    "Note that: $\\forall n, \\; y_n(\\mathbf{w}^Tx_n + b) \\geq 1$\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "Eq. (1) can be turned to a constrained optimization problem as follows:\n",
    "\\begin{equation}\n",
    "\\tag{2}\n",
    "(\\mathbf{w},b) = arg\\;\\underset{\\mathbf{w},b}{min} \\frac{1}{2} {\\left \\| \\mathbf{w} \\right \\|}_2^2\n",
    "\\end{equation}\n",
    "subject to\n",
    "$$1-y_n(\\mathbf{w}^Tx_n+b) \\leq 0,\\; \\forall n=1,2,...,N$$\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lagrangian of SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "Lagrangian of (2) is:\n",
    "\\begin{equation}\n",
    "\\tag{3}\n",
    "\\mathbf{L}(\\mathbf{w},b,\\lambda) = \\frac{1}{2} {\\left \\| \\mathbf{w} \\right \\|}_2^2 \\;+\\; \\sum_{n=1}^{N}\\lambda_n(1-y_n(\\mathbf{w}^Tx_n+b))\n",
    "\\end{equation}\n",
    "with\n",
    "$\\lambda=[\\lambda_1,\\lambda_2,...,\\lambda_N]^T$ and $\\lambda_n \\geq 0,\\;\\forall n=1,2,...,N$\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Dual Lagrangian function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "\\begin{equation}\n",
    "\\tag{4}\n",
    "g(\\lambda) = \\underset{\\mathbf{w},b}{min}\\;\\mathbf{L}(\\mathbf{w},b,\\lambda)\n",
    "\\end{equation}\n",
    "with $$\\lambda\\succeq0$$\n",
    "\n",
    "By solving (4), we get\n",
    "\\begin{equation}\n",
    "\\tag{5}\n",
    "g(\\lambda)=\\sum_{n=1}^{N}\\lambda_n - \\frac{1}{2}\\sum_{n=1}^{N}\\sum_{m=1}^{N}\\lambda_n\\lambda_my_ny_m\\mathbf{x}_n^T\\mathbf{x}_m\n",
    "\\end{equation}\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matrix Representation**\n",
    "<font size=\"3\">\n",
    "Set $\\mathbf{V}=[y_1x_1,y_2x_2,...,y_Nx_N]$\n",
    "and vector $\\mathbf{1}=[1,1,...,1]^T$, $g(\\lambda)$ in (5) can then be represented as:\n",
    "\\begin{equation}\n",
    "\\tag{6}\n",
    "g(\\lambda)=-\\frac{1}{2}\\lambda^T\\mathbf{V}^T\\mathbf{V}\\lambda + \\mathbf{1}^T\\lambda\n",
    "\\end{equation}\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "Let $\\mathbf{K}=\\mathbf{V}^T\\mathbf{V}$, we can prove that $\\mathbf{K} \\succeq 0$\n",
    "\n",
    "(6) can be then represented as:\n",
    "\\begin{equation}\n",
    "\\tag{7}\n",
    "g(\\lambda) = -\\frac{1}{2}\\lambda^T\\mathbf{K}\\lambda + \\mathbf{1}^T\\lambda\n",
    "\\end{equation}\n",
    "\n",
    "$g(\\lambda)$ is a concave function\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Dual Lagrangian problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "We want to solve the dual problem of (7), which is:\n",
    "\\begin{equation}\n",
    "\\tag{8}\n",
    "\\lambda=arg\\; \\underset{\\lambda}{max}\\;g(\\lambda)\n",
    "\\end{equation}\n",
    "\n",
    "subject to: $$\\lambda \\succeq 0$$\n",
    "$$\\sum_{n=1}^{N}\\lambda_ny_n=0$$\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "We can prove that\n",
    "\\begin{equation}\n",
    "\\tag{9}\n",
    "b = \\frac{1}{N_{S}}\\sum_{n\\in S}(y_n-\\mathbf{w}^Tx_n) = \\frac{1}{N_{S}}\\sum_{n\\in S} \\left ( y_n - \\sum_{m \\in S} \\lambda_my_mx_m^Tx_n \\right )\n",
    "\\end{equation}\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "\\begin{equation}\n",
    "\\tag{10}\n",
    "\\mathbf{w} = \\sum_{m \\in S} \\lambda_my_mx_m\n",
    "\\end{equation}\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-programming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "np.random.seed(22)\n",
    "\n",
    "#Generate simulation data\n",
    "means = [[2, 2], [4, 2]]\n",
    "cov = [[.3, .2], [.2, .3]]\n",
    "N = 10\n",
    "X0 = np.random.multivariate_normal(means[0], cov, N) # class 1\n",
    "X1 = np.random.multivariate_normal(means[1], cov, N) # class -1 \n",
    "X = np.concatenate((X0.T, X1.T), axis = 1) # all data \n",
    "y = np.concatenate((np.ones((1, N)), -1*np.ones((1, N))), axis = 1) # labels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Solving equation (8) by using CVXOPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = \n",
      "[[8.54018321e-01 2.89132533e-10 1.37095535e+00 6.36030818e-10\n",
      "  4.04317408e-10 8.82390106e-10 6.35001881e-10 5.49567576e-10\n",
      "  8.33359230e-10 1.20982928e-10 6.86678649e-10 1.25039745e-10\n",
      "  2.22497367e+00 4.05417905e-09 1.26763684e-10 1.99008949e-10\n",
      "  2.13742578e-10 1.51537487e-10 3.75329509e-10 3.56161975e-10]]\n"
     ]
    }
   ],
   "source": [
    "from cvxopt import matrix, solvers\n",
    "# build K\n",
    "V = np.concatenate((X0.T, -X1.T), axis = 1)\n",
    "K = matrix(V.T.dot(V)) # see definition of V, K near eq (6)\n",
    "\n",
    "p = matrix(-np.ones((2*N, 1))) # all-one vector \n",
    "# build A, b, G, h \n",
    "G = matrix(-np.eye(2*N)) # for all lambda_n >= 0\n",
    "h = matrix(np.zeros((2*N, 1)))\n",
    "A = matrix(y) # the equality constrain is actually y^T lambda = 0\n",
    "b = matrix(np.zeros((1, 1))) \n",
    "solvers.options['show_progress'] = False\n",
    "sol = solvers.qp(K, p, G, h, A, b)\n",
    "\n",
    "l = np.array(sol['x'])\n",
    "print('lambda = ')\n",
    "print(l.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w =  [[-2.00984381  0.64068336]]\n",
      "b =  4.668560633868111\n"
     ]
    }
   ],
   "source": [
    "epsilon = 1e-6 # just a small number, greater than 1e-9\n",
    "S = np.where(l > epsilon)[0]\n",
    "\n",
    "VS = V[:, S]\n",
    "XS = X[:, S]\n",
    "yS = y[:, S]\n",
    "lS = l[S]\n",
    "# calculate w and b\n",
    "w = VS.dot(lS)\n",
    "b = np.mean(yS.T - w.T.dot(XS))\n",
    "\n",
    "print('w = ', w.T)\n",
    "print('b = ', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w =  [[-2.00971102  0.64194082]]\n",
      "b =  [4.66595309]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "y1 = y.reshape((2*N,))\n",
    "X1 = X.T # each sample is one row\n",
    "clf = SVC(kernel = 'linear', C = 1e5) # just a big number \n",
    "\n",
    "clf.fit(X1, y1) \n",
    "\n",
    "w = clf.coef_\n",
    "b = clf.intercept_\n",
    "print('w = ', w)\n",
    "print('b = ', b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
